{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTENT CLASSIFICATION\n",
    "\n",
    "## PROJECT WORK #2 - NLP - FEUP\n",
    "### Filippo Comastri - Benedek Lellei - Amanda Oliveira \n",
    "\n",
    "The problem consists of classify queries into different intent classes. Queries are very short sentences, usually some questions or prompt commands about specific topics.\n",
    "\n",
    "The propose of the project is to try large pretrained language models to accomlish the above task and compare the results with those of basic natural language processing techniques and \"traditional\" machine learning classification methods tried with the first assignment.\n",
    "\n",
    "We tried four different models found on Huggingface to see the performance of trasformer-based deep neural networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import pipeline\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import math\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "def get_df_hf(oos=False) :\n",
    "    with open('data_full.json') as json_file: \n",
    "        data_dict = json.load(json_file) \n",
    "\n",
    "    train_data = data_dict['train']\n",
    "    val_data = data_dict['val']\n",
    "    test_data = data_dict['test']\n",
    "\n",
    "    oos_train = data_dict['oos_train']\n",
    "    oos_val = data_dict['oos_val']\n",
    "    oos_test = data_dict['oos_test']\n",
    "\n",
    "\n",
    "    train_df = pd.DataFrame(train_data, columns =['query', 'label'])\n",
    "    val_df = pd.DataFrame(val_data, columns =['query', 'label'])\n",
    "    test_df = pd.DataFrame(test_data, columns =['query', 'label'])\n",
    "\n",
    "    train_oos_df = pd.DataFrame(oos_train,columns=['query','label'])\n",
    "    val_oos_df = pd.DataFrame(oos_val,columns=['query','label'])\n",
    "    test_oos_df = pd.DataFrame(oos_test,columns=['query','label'])\n",
    "\n",
    "    if oos :\n",
    "        # Concatenate dataframes to consider oos as a specific intent\n",
    "        train_df = pd.concat([train_df,train_oos_df])\n",
    "        val_df = pd.concat([val_df,val_oos_df])\n",
    "        test_df = pd.concat([test_df,test_oos_df])\n",
    "\n",
    "    unique_labels = train_df['label'].unique()\n",
    "    labels_dict = {i: v for i, v in enumerate(unique_labels)}\n",
    "\n",
    "    train_df['label'], _ = pd.factorize(train_df['label'])\n",
    "    val_df['label'], _ = pd.factorize(val_df['label'])\n",
    "    test_df['label'], _ = pd.factorize(test_df['label'])\n",
    "\n",
    "    # Map the integer labels to string labels\n",
    "    #df['label'] = label_mapping.take(df['label'])\n",
    "    \n",
    "    return Dataset.from_pandas(train_df), Dataset.from_pandas(val_df), Dataset.from_pandas(test_df), labels_dict\n",
    "\n",
    "train_df, val_df, test_df, label_mapping = get_df_hf()\n",
    "train_valid_test_dataset = DatasetDict({\n",
    "    'train': train_df,\n",
    "    'validation': val_df,\n",
    "    'test': test_df\n",
    "})\n",
    "\n",
    "train_valid_test_dataset\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
