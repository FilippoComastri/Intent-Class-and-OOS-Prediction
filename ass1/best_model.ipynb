{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c3ef62",
   "metadata": {},
   "source": [
    "# Chose the Best Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c04791",
   "metadata": {},
   "source": [
    "## Load the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a3abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_df(oos = True, domains = False) :\n",
    "    with open('data_full.json') as json_file: \n",
    "        data_dict = json.load(json_file) \n",
    "\n",
    "    train_data = data_dict['train']\n",
    "    val_data = data_dict['val']\n",
    "    test_data = data_dict['test']\n",
    "\n",
    "    oos_train = data_dict['oos_train']\n",
    "    oos_val = data_dict['oos_val']\n",
    "    oos_test = data_dict['oos_test']\n",
    "\n",
    "\n",
    "    train_df = pd.DataFrame(train_data, columns =['query', 'intent'])\n",
    "    val_df = pd.DataFrame(val_data, columns =['query', 'intent'])\n",
    "    test_df = pd.DataFrame(test_data, columns =['query', 'intent'])\n",
    "\n",
    "    train_oos_df = pd.DataFrame(oos_train,columns=['query','intent'])\n",
    "    val_oos_df = pd.DataFrame(oos_val,columns=['query','intent'])\n",
    "    test_oos_df = pd.DataFrame(oos_test,columns=['query','intent'])\n",
    "\n",
    "    if oos :\n",
    "        # Concatenate dataframes to consider oos as a specific intent\n",
    "        train_df = pd.concat([train_df,train_oos_df])\n",
    "        val_df = pd.concat([val_df,val_oos_df])\n",
    "        test_df = pd.concat([test_df,test_oos_df])\n",
    "    \n",
    "    train_df =pd.concat([train_df,val_df])\n",
    "\n",
    "    if domains:\n",
    "        with open('domains.json') as json_file:\n",
    "            domain_dict = json.load(json_file)\n",
    "        inv_domain_dict = {}\n",
    "        for domainKey in domain_dict.keys():\n",
    "            for intent in domain_dict[domainKey]:\n",
    "                inv_domain_dict[intent] = domainKey\n",
    "        if oos:\n",
    "            inv_domain_dict['oos']='oos'\n",
    "        train_df['domain'] = train_df.apply(lambda row: inv_domain_dict[row['intent']],axis=1)\n",
    "        test_df['domain'] = test_df.apply(lambda row: inv_domain_dict[row['intent']],axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "df_train, df_test = get_df(oos=False,domains=True)\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb7201",
   "metadata": {},
   "source": [
    "## Pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a2c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "def utils_preprocess_text(text, flg_stemm=True, flg_lemm=False, lst_stopwords=None):\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming \n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation \n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e109edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_train[\"query_clean\"] = df_train[\"query\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True))\n",
    "df_test[\"query_clean\"] = df_test[\"query\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6093f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_as_lst(corpus):\n",
    "   ## create list of lists of unigrams\n",
    "   lst_corpus = []\n",
    "   for string in corpus:\n",
    "      lst_words = string.split()\n",
    "      lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words), 1)]\n",
    "      lst_corpus.append(lst_grams)\n",
    "   return lst_corpus\n",
    "\n",
    "# Prepare the corpus to be trained by Word2Vec\n",
    "train_corpus = corpus_as_lst(df_train['query_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dcecc",
   "metadata": {},
   "source": [
    "## Trainging word embeddings\n",
    "Train a word embedding with the vocalburay of the queries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35c39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training word embeddings\n",
    "wc_model = gensim.models.word2vec.Word2Vec(train_corpus, vector_size=300,   window=8, min_count=1, sg=1, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e315ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_mean_vector(embeddings, text):\n",
    "    tokens = text.split()\n",
    "    vec = []\n",
    "    for i in range(len(tokens)):\n",
    "        try:\n",
    "            vec.append(embeddings.get_vector(tokens[i]))\n",
    "        except KeyError:\n",
    "            True   # simply ignore out-of-vocabulary tokens\n",
    "    if(len(vec)!=0):\n",
    "        return [sum([row[j] for row in vec]) / len(vec) for j in range(len(vec[0]))]\n",
    "    else : \n",
    "        return []\n",
    "    \n",
    "def get_word_embdeddings(lst_corpus, model):\n",
    "    embeddings_corpus = []\n",
    "    for c in lst_corpus:\n",
    "        mean_vec = text_to_mean_vector(model.wv, c)\n",
    "        if(len(mean_vec)!=0):\n",
    "            embeddings_corpus.append(mean_vec)\n",
    "        else:\n",
    "            embeddings_corpus.append(np.zeros(model.wv.vector_size,))\n",
    "    return np.array(embeddings_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837f6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting word embeddings\n",
    "X_train_we = get_word_embdeddings(df_train['query_clean'], wc_model)\n",
    "X_test_we = get_word_embdeddings(df_test['query_clean'], wc_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a853c6f",
   "metadata": {},
   "source": [
    "### Train the Models \n",
    "Train all the models chosed and print his respectives results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006eae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94571174",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(multi_class='multinomial', max_iter=300),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(max_depth=2, random_state=0),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "]\n",
    "model_names = [\n",
    "    \"   Logistic Regression\",\n",
    "    \"Support Vector Machine\",\n",
    "    \"         Decision Tree\",\n",
    "    \"         Random Forest\",\n",
    "    \"  Gaussian Naive Bayes\", \n",
    "    \"Multi-Layer Perceptron\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69abeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, df_train, df_test, domains = False):\n",
    "    y_train = (df_train['domain'].values) if domains else (df_train['intent'].values)\n",
    "    return model.fit(X_train, y_train)\n",
    "\n",
    "def predic_of_model(model_fited, X_test, domains = False):\n",
    "    y_test = df_test['domain'].values if domains else df_test['intent'].values\n",
    "    y_pred = model_fited.predict(X_test)\n",
    "   \n",
    "    return y_pred, y_test, X_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5329c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished train model:     Logistic Regression\n",
      "finished train model:  Support Vector Machine\n",
      "finished train model:           Decision Tree\n",
      "finished train model:           Random Forest\n",
      "finished train model:    Gaussian Naive Bayes\n",
      "finished train model:  Multi-Layer Perceptron\n",
      "[LogisticRegression(max_iter=300, multi_class='multinomial'), SVC(probability=True), DecisionTreeClassifier(random_state=0), RandomForestClassifier(max_depth=2, random_state=0), GaussianNB(), MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
      "              solver='lbfgs')]\n"
     ]
    }
   ],
   "source": [
    "fited_models = []\n",
    "for model, name in zip(models, model_names):\n",
    "    fited_model = train_model(model, X_train_we, df_train, df_test, domains = False)\n",
    "    print(\"finished train model: \", name)\n",
    "    fited_models.append(fited_model)\n",
    "\n",
    "print(fited_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a2313",
   "metadata": {},
   "source": [
    "### Report the model's results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b27d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42348371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReport(model, name, X_test, y_test, y_pred):\n",
    "    print(\"################# \" + name.upper() + '#################')\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels= model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig, ax = plt.subplots(figsize=(100,100))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.show()\n",
    "    # score\n",
    "    print(name + \": {:.4f}%\".format(model.score(X_test, y_test) * 100))\n",
    "    # confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # report\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15071a40",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predic_of_model() missing 1 required positional argument: 'X_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3347f5b86012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfited_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredic_of_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfited_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprintReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfited_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predic_of_model() missing 1 required positional argument: 'X_test'"
     ]
    }
   ],
   "source": [
    "for fited_model, name in zip(models, model_names):\n",
    "    y_pred, y_test, X_test = predic_of_model(fited_model, domains = False)\n",
    "    printReport(fited_model, name, X_test, y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa7259",
   "metadata": {},
   "source": [
    "### External exploration\n",
    "The class(intent) with the worst result using Logist Regration is \"yes\", \"goodbye\" lets check what it is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#query = input(\"Enter query: \")\n",
    "query = \"Set my alarm to 6 am\"\n",
    "# preprocess\n",
    "query = utils_preprocess_text(query)\n",
    "\n",
    "# vectorize the review\n",
    "V2 = vectorizer.transform([query]).toarray()\n",
    "V = get_word_embdeddings( query, wc_model)\n",
    "\n",
    "print(query)\n",
    "print(V.shape)\n",
    "print(V)\n",
    "clf = fited_models[0];\n",
    "print(clf)\n",
    "print(clf.predict(V2));\n",
    "print(clf.predict(V));\n",
    "print(clf.predict(query.split()));\n",
    "print(clf.predict(V)[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978e59f",
   "metadata": {},
   "source": [
    "### Now Using raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### no word embedings\n",
    "fited_models = []\n",
    "df_train, df_test = get_df(oos=False,domains=True)\n",
    "train_corpus = corpus_as_lst(df_train['query'])\n",
    "txt = [\" \".join(x) for x in train_corpus]\n",
    "#print(\" \".join(txt))\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(txt).toarray()\n",
    "print(\"HERE\", \"vectorize done\")\n",
    "for model, name in zip(models, model_names):\n",
    "    fited_model = train_model(model, X_train, df_train, df_test, domains = False)\n",
    "    print(\"finished train model: \", name)\n",
    "    fited_models.append(fited_model)\n",
    "\n",
    "print(fited_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f55724",
   "metadata": {},
   "source": [
    "### Chossing the best model\n",
    "Run all fit all the models selected if difrent paramters for chose the best model with the best score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chossing the best model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_params = {\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(multi_class='auto', max_iter=300),\n",
    "        'params': {\n",
    "            'solver': ['sag', 'saga','newton-cg', 'lbfgs'],\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'Multi-Layer Perceptron': {\n",
    "        'model': MLPClassifier(),\n",
    "        'params' : {\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'C': [1, 10, 20],\n",
    "            'kernel': ['sigmoid', 'precomputed'],\n",
    "            'cache_size':(200)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6583c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "classByDomain = False\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    if classByDomain:\n",
    "        y_train = df_train['domain'].values\n",
    "        y_test = df_test['domain'].values\n",
    "    else:\n",
    "        y_train = df_train['intent'].values\n",
    "        y_test = df_test['intent'].values\n",
    "        \n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
